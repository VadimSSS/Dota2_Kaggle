{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns with NaN:\n",
      "first_blood_time\n",
      "first_blood_team\n",
      "first_blood_player1\n",
      "first_blood_player2\n",
      "radiant_bottle_time\n",
      "radiant_courier_time\n",
      "radiant_flying_courier_time\n",
      "radiant_first_ward_time\n",
      "dire_bottle_time\n",
      "dire_courier_time\n",
      "dire_flying_courier_time\n",
      "dire_first_ward_time\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/ML/project/features.csv\", index_col='match_id')\n",
    "y_train = data['radiant_win']\n",
    "x = data.drop(['duration', 'radiant_win', 'tower_status_radiant', \n",
    "               'tower_status_dire', 'barracks_status_radiant', \n",
    "               'barracks_status_dire'], axis = 1)\n",
    "print('columns with NaN:')\n",
    "for i in x.columns:\n",
    "    if x[i].hasnans:\n",
    "        #printing names of column with NaN\n",
    "        print(i)\n",
    "        x[i] = x[i].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 10 score 0.678414075423 Time: 0:03:31.908786\n",
      "n: 20 score 0.692392722997 Time: 0:06:38.853878\n",
      "n: 30 score 0.69886478311 Time: 0:09:07.724268\n",
      "n: 40 score 0.702504635693 Time: 0:12:20.934718\n",
      "n: 50 score 0.705227734735 Time: 0:14:30.780691\n"
     ]
    }
   ],
   "source": [
    "for trees in [10, 20, 30, 40, 50]:\n",
    "    start_time = datetime.datetime.now()\n",
    "    model = GradientBoostingClassifier(n_estimators=trees, random_state=17, learning_rate=0.2)\n",
    "    cv = KFold(len(y_train), n_folds=5, random_state=17, shuffle=True)\n",
    "    scores = cross_val_score(model, x, y_train, cv=cv, scoring='roc_auc')\n",
    "    #printing results of validation\n",
    "    print('n:', trees, 'score', scores.mean(), 'Time:', datetime.datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Preparation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/ML/project/features.csv\", index_col='match_id')\n",
    "y_train = data['radiant_win']\n",
    "x = data.drop(['duration', 'radiant_win', 'tower_status_radiant', \n",
    "               'tower_status_dire', 'barracks_status_radiant', 'barracks_status_dire'], axis = 1)\n",
    "x.fillna(0, inplace = True)\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.0001   Score: 0.711175170448 Time: 0:00:14.624822\n",
      "C: 0.001   Score: 0.716138080286 Time: 0:00:24.645288\n",
      "C: 0.01   Score: 0.716325474946 Time: 0:00:32.295612\n",
      "C: 0.1   Score: 0.716300460534 Time: 0:00:33.788337\n",
      "C: 1.0   Score: 0.716296998325 Time: 0:00:32.740246\n",
      "C: 10.0   Score: 0.716296816332 Time: 0:00:32.956178\n",
      "C: 100.0   Score: 0.716296764514 Time: 0:00:33.335013\n"
     ]
    }
   ],
   "source": [
    "c = 0.0001\n",
    "while c <=100:\n",
    "    start_time = datetime.datetime.now()\n",
    "    model = LogisticRegression(C=c, penalty = 'l2', random_state = 31)\n",
    "    cv = KFold(len(y_train), n_folds=5, random_state=17, shuffle=True)\n",
    "    scores = cross_val_score(model, x_train_scaled, y_train, cv=cv, scoring='roc_auc')\n",
    "    #printing results of validation\n",
    "    print('C:', c, '  Score:', scores.mean(), 'Time:', datetime.datetime.now() - start_time)\n",
    "    c *= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete columns and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.01   Score: 0.716366662587 Time: 0:00:32.523235\n"
     ]
    }
   ],
   "source": [
    "x_new = x.drop(['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero',\n",
    "                'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero'], axis = 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_new)\n",
    "c = 0.01\n",
    "start_time = datetime.datetime.now()\n",
    "model = LogisticRegression(C=c, penalty = 'l2', random_state = 31)\n",
    "cv = KFold(len(y_train), n_folds=5, random_state=17, shuffle=True)\n",
    "scores = cross_val_score(model, x_train_scaled, y_train, cv=cv, scoring='roc_auc')\n",
    "print('C:', c, '  Score:', scores.mean(), 'Time:', datetime.datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique hero: 108\n",
      "X_new size  (97230, 203)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/ML/project/features.csv\", index_col='match_id')\n",
    "\n",
    "y_train = data['radiant_win']\n",
    "x = data.drop(['duration', 'radiant_win', 'tower_status_radiant', \n",
    "               'tower_status_dire', 'barracks_status_radiant', 'barracks_status_dire'], axis = 1)\n",
    "x.fillna(0, inplace = True)\n",
    "\n",
    "#searching number of unique heroes\n",
    "n = []\n",
    "for i in range(5):\n",
    "    r = x['r%d_hero' % (i+1)].unique().tolist()\n",
    "    d = x['d%d_hero' % (i+1)].unique().tolist()\n",
    "    n = np.concatenate((n, r, d))\n",
    "n = np.unique(n)\n",
    "print('unique hero:', len(n))\n",
    "\n",
    "N_hero = int(n.max()) \n",
    "X_pick = np.zeros((x.shape[0], N_hero))\n",
    "for i, match_id in enumerate(x.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, x.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, x.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "# dataframe with heroes\n",
    "labels = map(lambda x: 'hero_%d' % (x+1), range(0, X_pick.shape[1]))\n",
    "x_hero = pd.DataFrame(X_pick, columns=labels)\n",
    "\n",
    "x_new = x.drop(['lobby_type', 'r1_hero', 'r2_hero', \n",
    "                'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', \n",
    "                'd3_hero', 'd4_hero', 'd5_hero'], axis = 1)\n",
    "x_new = np.concatenate((x_new, x_hero), axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x_new)\n",
    "print('X_new size ', x_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation with bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97230\n",
      "C: 0.01   Score: 0.751885092001 Time: 0:00:53.292816\n"
     ]
    }
   ],
   "source": [
    "c = 0.01\n",
    "while c <=0.01:\n",
    "    start_time = datetime.datetime.now()\n",
    "    model = LogisticRegression(C=c, penalty = 'l2', random_state = 31)\n",
    "    cv = KFold(len(y_train), n_folds=5, random_state=17, shuffle=True)\n",
    "    print(len(y_train))\n",
    "    scores = cross_val_score(model, x_scaled, y_train, cv=cv, scoring='roc_auc')\n",
    "    print('C:', c, '  Score:', scores.mean(), 'Time:', datetime.datetime.now() - start_time)\n",
    "    c *= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=31, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with features_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 0.00372237596433\n",
      "max: 0.996277624036\n"
     ]
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"C:/ML/project/features_test.csv\", index_col='match_id')\n",
    "x = data_test\n",
    "\n",
    "x.fillna(0, inplace = True)\n",
    "\n",
    "#searching number of unique heroes\n",
    "\n",
    "n = []\n",
    "for i in range(5):\n",
    "    r = x['r%d_hero' % (i+1)].unique().tolist()\n",
    "    d = x['d%d_hero' % (i+1)].unique().tolist()\n",
    "    n = np.concatenate((n, r, d))\n",
    "n = np.unique(n)\n",
    "\n",
    "N_hero = int(n.max()) \n",
    "X_pick = np.zeros((x.shape[0], N_hero))\n",
    "for i, match_id in enumerate(x.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, x.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, x.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "# dataframe with heroes\n",
    "labels = map(lambda x: 'hero_%d' % (x+1), range(0, X_pick.shape[1]))\n",
    "x_hero = pd.DataFrame(X_pick, columns=labels)\n",
    "\n",
    "x_new = x.drop(['lobby_type', 'r1_hero', 'r2_hero', \n",
    "                'r3_hero', 'r4_hero', 'r5_hero', 'd1_hero', 'd2_hero', \n",
    "                'd3_hero', 'd4_hero', 'd5_hero'], axis = 1)\n",
    "x_new = np.concatenate((x_new, x_hero), axis=1)\n",
    "\n",
    "\n",
    "x_new_scaled = scaler.transform(x_new)\n",
    "\n",
    "#print('Matrix size ', x)\n",
    "print('min:', model.predict_proba(x_new_scaled).min())\n",
    "print('max:', model.predict_proba(x_new_scaled).max())\n",
    "pred = model.predict_proba(x_new_scaled)\n",
    "submission = pd.DataFrame({'match_id' : x.index, 'radiant_win' : pred[:,1]})\n",
    "submission.to_csv('C:/ML/Project/results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
